{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "N=40000\n",
    "L=4\n",
    "X = L*np.random.rand(N,2) \n",
    "X[:,0] = X[:,0]-L/2\n",
    "X[:,1] = X[:,1]-L/2\n",
    "\n",
    "Y = np.zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "    if (X[i,0]-0.7)**2+(X[i,1]-0.6)**2<0.49:\n",
    "        Y[i]=1\n",
    "    else:\n",
    "        Y[i]=1\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=1)\n",
    "plt.show()\n",
    "\n",
    "data = X\n",
    "labels = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hid_layer: [2 , 2]\n",
      "progress : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 12:30:00.081810 140283586758464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: {'loss': [0.5599149465560913], 'categorical_accuracy': [0.840225]}\n",
      "epoch 2: {'loss': [0.5568646192550659], 'categorical_accuracy': [0.8406]}\n",
      "epoch 3: {'loss': [0.5518420338630676], 'categorical_accuracy': [0.84120834]}\n",
      "epoch 4: {'loss': [0.5449367314577103], 'categorical_accuracy': [0.841775]}\n",
      "epoch 5: {'loss': [0.5362864375114441], 'categorical_accuracy': [0.841885]}\n",
      "epoch 6: {'loss': [0.5260788301626841], 'categorical_accuracy': [0.842]}\n",
      "epoch 7: {'loss': [0.5145461899893624], 'categorical_accuracy': [0.8685036]}\n",
      "epoch 8: {'loss': [0.5019585229456425], 'categorical_accuracy': [0.903225]}\n",
      "epoch 9: {'loss': [0.48893869585461086], 'categorical_accuracy': [0.903225]}\n",
      "epoch 10: {'loss': [0.47573149502277373], 'categorical_accuracy': [0.903225]}\n",
      "epoch 11: {'loss': [0.4622964073311199], 'categorical_accuracy': [0.903225]}\n",
      "epoch 12: {'loss': [0.4488297204176585], 'categorical_accuracy': [0.903225]}\n",
      "epoch 13: {'loss': [0.4354848563671112], 'categorical_accuracy': [0.903225]}\n",
      "epoch 14: {'loss': [0.42235729311193737], 'categorical_accuracy': [0.903225]}\n",
      "epoch 15: {'loss': [0.4094746232032776], 'categorical_accuracy': [0.903225]}\n",
      "epoch 16: {'loss': [0.39687170647084713], 'categorical_accuracy': [0.903225]}\n",
      "epoch 17: {'loss': [0.3845765012152055], 'categorical_accuracy': [0.903225]}\n",
      "epoch 18: {'loss': [0.37262949844201404], 'categorical_accuracy': [0.903225]}\n",
      "epoch 19: {'loss': [0.3611044632761102], 'categorical_accuracy': [0.903225]}\n",
      "epoch 20: {'loss': [0.3500425979495049], 'categorical_accuracy': [0.903225]}\n",
      "epoch 21: {'loss': [0.33943599462509155], 'categorical_accuracy': [0.903225]}\n",
      "epoch 22: {'loss': [0.329240697351369], 'categorical_accuracy': [0.903225]}\n",
      "epoch 23: {'loss': [0.3193927355434584], 'categorical_accuracy': [0.903225]}\n",
      "epoch 24: {'loss': [0.3098239017029603], 'categorical_accuracy': [0.903225]}\n",
      "epoch 25: {'loss': [0.30058865785598754], 'categorical_accuracy': [0.903225]}\n",
      "epoch 26: {'loss': [0.29180390445085674], 'categorical_accuracy': [0.903225]}\n",
      "epoch 27: {'loss': [0.28345227903789944], 'categorical_accuracy': [0.903225]}\n",
      "epoch 28: {'loss': [0.2756445088556835], 'categorical_accuracy': [0.903225]}\n",
      "epoch 29: {'loss': [0.26841465255309793], 'categorical_accuracy': [0.903225]}\n",
      "epoch 30: {'loss': [0.26176176766554515], 'categorical_accuracy': [0.903225]}\n",
      "epoch 31: {'loss': [0.25567330948768124], 'categorical_accuracy': [0.903225]}\n",
      "epoch 32: {'loss': [0.25010283663868904], 'categorical_accuracy': [0.903225]}\n",
      "epoch 33: {'loss': [0.24499476091428238], 'categorical_accuracy': [0.903225]}\n",
      "epoch 34: {'loss': [0.24032826195744908], 'categorical_accuracy': [0.903225]}\n",
      "epoch 35: {'loss': [0.23607341051101685], 'categorical_accuracy': [0.903225]}\n",
      "epoch 36: {'loss': [0.23218392373787033], 'categorical_accuracy': [0.903225]}\n",
      "epoch 37: {'loss': [0.22861255665083188], 'categorical_accuracy': [0.903225]}\n",
      "epoch 38: {'loss': [0.22531800521047493], 'categorical_accuracy': [0.903225]}\n",
      "epoch 39: {'loss': [0.22227937900103056], 'categorical_accuracy': [0.903225]}\n",
      "epoch 40: {'loss': [0.21946123018860816], 'categorical_accuracy': [0.903225]}\n",
      "epoch 41: {'loss': [0.2168348606039838], 'categorical_accuracy': [0.903225]}\n",
      "epoch 42: {'loss': [0.21437637685310273], 'categorical_accuracy': [0.903225]}\n",
      "epoch 43: {'loss': [0.2120530231054439], 'categorical_accuracy': [0.903225]}\n",
      "epoch 44: {'loss': [0.20984020185741512], 'categorical_accuracy': [0.903225]}\n",
      "epoch 45: {'loss': [0.20773024393452538], 'categorical_accuracy': [0.903225]}\n",
      "epoch 46: {'loss': [0.20570505831552588], 'categorical_accuracy': [0.903225]}\n",
      "epoch 47: {'loss': [0.20374021029218714], 'categorical_accuracy': [0.903225]}\n",
      "epoch 48: {'loss': [0.20182749877373377], 'categorical_accuracy': [0.903225]}\n",
      "epoch 49: {'loss': [0.19996487182013842], 'categorical_accuracy': [0.903225]}\n",
      "epoch 50: {'loss': [0.19815151154994964], 'categorical_accuracy': [0.903225]}\n",
      "epoch 51: {'loss': [0.1963999998920104], 'categorical_accuracy': [0.903225]}\n",
      "epoch 52: {'loss': [0.19472483430917448], 'categorical_accuracy': [0.903225]}\n",
      "epoch 53: {'loss': [0.1931231772562243], 'categorical_accuracy': [0.903225]}\n",
      "epoch 54: {'loss': [0.19157946440908644], 'categorical_accuracy': [0.903225]}\n",
      "epoch 55: {'loss': [0.19008746201341803], 'categorical_accuracy': [0.903225]}\n",
      "epoch 56: {'loss': [0.1886443453175681], 'categorical_accuracy': [0.903225]}\n",
      "epoch 57: {'loss': [0.18724482964005387], 'categorical_accuracy': [0.903225]}\n",
      "epoch 58: {'loss': [0.18588718001184792], 'categorical_accuracy': [0.903225]}\n",
      "epoch 59: {'loss': [0.1845718316607556], 'categorical_accuracy': [0.903225]}\n",
      "epoch 60: {'loss': [0.18330703725417455], 'categorical_accuracy': [0.903225]}\n",
      "epoch 61: {'loss': [0.18208997269145777], 'categorical_accuracy': [0.903225]}\n",
      "epoch 62: {'loss': [0.18091906390843854], 'categorical_accuracy': [0.903225]}\n",
      "epoch 63: {'loss': [0.17979922512220958], 'categorical_accuracy': [0.903225]}\n",
      "epoch 64: {'loss': [0.17872942867688835], 'categorical_accuracy': [0.903225]}\n",
      "epoch 65: {'loss': [0.1777057118140734], 'categorical_accuracy': [0.903225]}\n",
      "epoch 66: {'loss': [0.17673281173814426], 'categorical_accuracy': [0.903225]}\n",
      "epoch 67: {'loss': [0.17581382705204524], 'categorical_accuracy': [0.903225]}\n",
      "epoch 68: {'loss': [0.17494798385921648], 'categorical_accuracy': [0.903225]}\n",
      "epoch 69: {'loss': [0.17413391388844754], 'categorical_accuracy': [0.903225]}\n",
      "epoch 70: {'loss': [0.1733768424817494], 'categorical_accuracy': [0.903225]}\n",
      "epoch 71: {'loss': [0.17267227613590133], 'categorical_accuracy': [0.903225]}\n",
      "epoch 72: {'loss': [0.1720159182118045], 'categorical_accuracy': [0.903225]}\n",
      "epoch 73: {'loss': [0.17141111378800378], 'categorical_accuracy': [0.903225]}\n",
      "epoch 74: {'loss': [0.17085594482518532], 'categorical_accuracy': [0.903225]}\n",
      "epoch 75: {'loss': [0.1703458046913147], 'categorical_accuracy': [0.903225]}\n",
      "epoch 76: {'loss': [0.1698790100452147], 'categorical_accuracy': [0.903225]}\n",
      "epoch 77: {'loss': [0.16944783519614826], 'categorical_accuracy': [0.903225]}\n",
      "epoch 78: {'loss': [0.1690472622330372], 'categorical_accuracy': [0.903225]}\n",
      "epoch 79: {'loss': [0.1686825778665422], 'categorical_accuracy': [0.903225]}\n",
      "epoch 80: {'loss': [0.16835046466439962], 'categorical_accuracy': [0.903225]}\n",
      "epoch 81: {'loss': [0.16804877015543573], 'categorical_accuracy': [0.903225]}\n",
      "epoch 82: {'loss': [0.16777556316881645], 'categorical_accuracy': [0.903225]}\n",
      "epoch 83: {'loss': [0.16752862714859376], 'categorical_accuracy': [0.903225]}\n",
      "epoch 84: {'loss': [0.16730546631983348], 'categorical_accuracy': [0.903225]}\n",
      "epoch 85: {'loss': [0.16709971200017368], 'categorical_accuracy': [0.903225]}\n",
      "epoch 86: {'loss': [0.16690872522980668], 'categorical_accuracy': [0.903225]}\n",
      "epoch 87: {'loss': [0.1667253172945702], 'categorical_accuracy': [0.903225]}\n",
      "epoch 88: {'loss': [0.16655829887498508], 'categorical_accuracy': [0.903225]}\n",
      "epoch 89: {'loss': [0.16640731056084793], 'categorical_accuracy': [0.903225]}\n",
      "epoch 90: {'loss': [0.16626161519024107], 'categorical_accuracy': [0.903225]}\n",
      "epoch 91: {'loss': [0.1661219555925537], 'categorical_accuracy': [0.903225]}\n",
      "epoch 92: {'loss': [0.165985065633836], 'categorical_accuracy': [0.903225]}\n",
      "epoch 93: {'loss': [0.1658520544728925], 'categorical_accuracy': [0.903225]}\n",
      "epoch 94: {'loss': [0.165733997809126], 'categorical_accuracy': [0.903225]}\n",
      "epoch 95: {'loss': [0.16562901750991219], 'categorical_accuracy': [0.903225]}\n",
      "epoch 96: {'loss': [0.16553097932289043], 'categorical_accuracy': [0.903225]}\n",
      "epoch 97: {'loss': [0.1654351038723877], 'categorical_accuracy': [0.903225]}\n",
      "epoch 98: {'loss': [0.16533819510012257], 'categorical_accuracy': [0.903225]}\n",
      "epoch 99: {'loss': [0.1652220275365945], 'categorical_accuracy': [0.903225]}\n",
      "epoch 100: {'loss': [0.16512531399726868], 'categorical_accuracy': [0.903225]}\n",
      "hid_layer: [2 , 3]\n",
      "progress : 0.16666666666666666\n",
      "epoch 1: {'loss': [0.8558048009872437], 'categorical_accuracy': [0.2943]}\n",
      "epoch 2: {'loss': [0.8505191504955292], 'categorical_accuracy': [0.2978375]}\n",
      "epoch 3: {'loss': [0.8418500622113546], 'categorical_accuracy': [0.3034]}\n",
      "epoch 4: {'loss': [0.8300218880176544], 'categorical_accuracy': [0.31248125]}\n",
      "epoch 5: {'loss': [0.8153531551361084], 'categorical_accuracy': [0.325125]}\n",
      "epoch 6: {'loss': [0.7983075579007467], 'categorical_accuracy': [0.34438333]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: {'loss': [0.779718245778765], 'categorical_accuracy': [0.36969644]}\n",
      "epoch 8: {'loss': [0.7599452212452888], 'categorical_accuracy': [0.40621564]}\n",
      "epoch 9: {'loss': [0.7394378847546048], 'categorical_accuracy': [0.4510389]}\n",
      "epoch 10: {'loss': [0.718668919801712], 'categorical_accuracy': [0.5046125]}\n",
      "epoch 11: {'loss': [0.6980430754748258], 'categorical_accuracy': [0.5637864]}\n",
      "epoch 12: {'loss': [0.6778889149427414], 'categorical_accuracy': [0.62495]}\n",
      "epoch 13: {'loss': [0.6584462569310114], 'categorical_accuracy': [0.6956288]}\n",
      "epoch 14: {'loss': [0.6398961203438895], 'categorical_accuracy': [0.7820339]}\n",
      "epoch 15: {'loss': [0.6223496993382772], 'categorical_accuracy': [0.8795317]}\n",
      "epoch 16: {'loss': [0.605832651257515], 'categorical_accuracy': [0.903225]}\n",
      "epoch 17: {'loss': [0.5902511337224174], 'categorical_accuracy': [0.903225]}\n",
      "epoch 18: {'loss': [0.5753974186049567], 'categorical_accuracy': [0.903225]}\n",
      "epoch 19: {'loss': [0.5611501806660703], 'categorical_accuracy': [0.903225]}\n",
      "epoch 20: {'loss': [0.547414892911911], 'categorical_accuracy': [0.903225]}\n",
      "epoch 21: {'loss': [0.5340573078110105], 'categorical_accuracy': [0.903225]}\n",
      "epoch 22: {'loss': [0.520809682932767], 'categorical_accuracy': [0.903225]}\n",
      "epoch 23: {'loss': [0.5073069074879522], 'categorical_accuracy': [0.903225]}\n",
      "epoch 24: {'loss': [0.49316812058289844], 'categorical_accuracy': [0.903225]}\n",
      "epoch 25: {'loss': [0.47799604296684267], 'categorical_accuracy': [0.903225]}\n",
      "epoch 26: {'loss': [0.4613735114152615], 'categorical_accuracy': [0.903225]}\n",
      "epoch 27: {'loss': [0.44272598293092513], 'categorical_accuracy': [0.903225]}\n",
      "epoch 28: {'loss': [0.42159750844751087], 'categorical_accuracy': [0.903225]}\n",
      "epoch 29: {'loss': [0.39852201116496117], 'categorical_accuracy': [0.903225]}\n",
      "epoch 30: {'loss': [0.37430402437845867], 'categorical_accuracy': [0.903225]}\n",
      "epoch 31: {'loss': [0.35020304783698053], 'categorical_accuracy': [0.903225]}\n",
      "epoch 32: {'loss': [0.3276580926030874], 'categorical_accuracy': [0.903225]}\n",
      "epoch 33: {'loss': [0.3078429301579793], 'categorical_accuracy': [0.903225]}\n",
      "epoch 34: {'loss': [0.29129767067292156], 'categorical_accuracy': [0.903225]}\n",
      "epoch 35: {'loss': [0.27793489609445843], 'categorical_accuracy': [0.903225]}\n",
      "epoch 36: {'loss': [0.26727477543883854], 'categorical_accuracy': [0.903225]}\n",
      "epoch 37: {'loss': [0.2586848180036287], 'categorical_accuracy': [0.903225]}\n",
      "epoch 38: {'loss': [0.25161412750419815], 'categorical_accuracy': [0.903225]}\n",
      "epoch 39: {'loss': [0.24562807381153107], 'categorical_accuracy': [0.903225]}\n",
      "epoch 40: {'loss': [0.24042560048401357], 'categorical_accuracy': [0.903225]}\n",
      "epoch 41: {'loss': [0.2358101686326469], 'categorical_accuracy': [0.903225]}\n",
      "epoch 42: {'loss': [0.23164113256193342], 'categorical_accuracy': [0.903225]}\n",
      "epoch 43: {'loss': [0.22779221139674963], 'categorical_accuracy': [0.903225]}\n",
      "epoch 44: {'loss': [0.22419452972032808], 'categorical_accuracy': [0.903225]}\n",
      "epoch 45: {'loss': [0.22080020937654707], 'categorical_accuracy': [0.903225]}\n",
      "epoch 46: {'loss': [0.21756877944521283], 'categorical_accuracy': [0.903225]}\n",
      "epoch 47: {'loss': [0.21446802134209492], 'categorical_accuracy': [0.903225]}\n",
      "epoch 48: {'loss': [0.21147922116021314], 'categorical_accuracy': [0.903225]}\n",
      "epoch 49: {'loss': [0.20859615778436466], 'categorical_accuracy': [0.903225]}\n",
      "epoch 50: {'loss': [0.20580266535282135], 'categorical_accuracy': [0.903225]}\n",
      "epoch 51: {'loss': [0.20309288770544762], 'categorical_accuracy': [0.903225]}\n",
      "epoch 52: {'loss': [0.20047996737636053], 'categorical_accuracy': [0.903225]}\n",
      "epoch 53: {'loss': [0.19797147613651347], 'categorical_accuracy': [0.903225]}\n",
      "epoch 54: {'loss': [0.19556165017463542], 'categorical_accuracy': [0.903225]}\n",
      "epoch 55: {'loss': [0.19327762668783013], 'categorical_accuracy': [0.903225]}\n",
      "epoch 56: {'loss': [0.19112953676709107], 'categorical_accuracy': [0.903225]}\n",
      "epoch 57: {'loss': [0.18933552686582533], 'categorical_accuracy': [0.903225]}\n",
      "epoch 58: {'loss': [0.18779441226145316], 'categorical_accuracy': [0.903225]}\n",
      "epoch 59: {'loss': [0.18633070537599467], 'categorical_accuracy': [0.903225]}\n",
      "epoch 60: {'loss': [0.1849336676299572], 'categorical_accuracy': [0.903225]}\n",
      "epoch 61: {'loss': [0.18360927627712], 'categorical_accuracy': [0.903225]}\n",
      "epoch 62: {'loss': [0.18235217299192183], 'categorical_accuracy': [0.903225]}\n",
      "epoch 63: {'loss': [0.18117142456864554], 'categorical_accuracy': [0.903225]}\n",
      "epoch 64: {'loss': [0.18005034187808633], 'categorical_accuracy': [0.903225]}\n",
      "epoch 65: {'loss': [0.17897891516868886], 'categorical_accuracy': [0.903225]}\n",
      "epoch 66: {'loss': [0.17796450898502814], 'categorical_accuracy': [0.903225]}\n",
      "epoch 67: {'loss': [0.17700082775372178], 'categorical_accuracy': [0.903225]}\n",
      "epoch 68: {'loss': [0.1760858198737397], 'categorical_accuracy': [0.903225]}\n",
      "epoch 69: {'loss': [0.17522594030352606], 'categorical_accuracy': [0.903225]}\n",
      "epoch 70: {'loss': [0.1744153212223734], 'categorical_accuracy': [0.903225]}\n",
      "epoch 71: {'loss': [0.1736572695450044], 'categorical_accuracy': [0.903225]}\n",
      "epoch 72: {'loss': [0.172950337951382], 'categorical_accuracy': [0.903225]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import activation_plot as aplt\n",
    "\n",
    "first_layer = [2,3,5]#10,20,30,90]\n",
    "second_layer = [2,3,5]#10,20,30,90]\n",
    "\n",
    "num_epoch = 100\n",
    "X_test = aplt.data_grid(grid=200,square_len=2)\n",
    "colors = aplt.get_color(X_test)\n",
    "\n",
    "for i in range(len(first_layer)):\n",
    "    for j in range(len(second_layer)):\n",
    "        print('hid_layer: [%i , %i]'%(first_layer[i],second_layer[j]))\n",
    "        print('progress :', int((i+j)/(len(first_layer)+len(second_layer))))\n",
    "        hid_layer_units = [first_layer[i], second_layer[j]]\n",
    "#     print('hid_layer: [%i]'%(first_layer[i]))\n",
    "#     print('progress :', i/(len(first_layer)))\n",
    "#     hid_layer_units = [first_layer[i]]\n",
    "        model = aplt.prepare_model(hid_layer_units,n_category = len(labels[0]))\n",
    "\n",
    "        net_name = '_'.join(str(e) for e in hid_layer_units)+'_2'\n",
    "        model_name = 'model_'+net_name\n",
    "        result_dir = 'iterasive_result/'+model_name\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        model_data_labels = [model, data, labels]\n",
    "        aplt.get_activation_prediction_transition(result_dir,num_epoch,X_test,model_data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process iterasive_result/model_10_2\n",
      "Process iterasive_result/model_20_2\n",
      "Process iterasive_result/model_30_2\n",
      "Process iterasive_result/model_60_2\n",
      "Process iterasive_result/model_90_2\n",
      "Process iterasive_result/model_180_2\n",
      "plot progress:99%\r"
     ]
    }
   ],
   "source": [
    "import activation_plot as aplt\n",
    "import os\n",
    "X_test = aplt.data_grid(grid=200,square_len=2)\n",
    "colors = aplt.get_color(X_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    first_layer = [10,20,30,60,90,180]\n",
    "    data_path_list = []\n",
    "    for i in first_layer:\n",
    "        path = 'iterasive_result/model_'+str(i)+'_2'\n",
    "        if os.path.exists(path):\n",
    "            data_path_list.append(path)\n",
    "    for data_path in data_path_list:\n",
    "        aplt.plot_data(data_path,X_test,colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress :0%\n",
      "Process iterasive_result/model_3_3_2\n",
      "progress :6%s:99%\n",
      "Process iterasive_result/model_3_5_2\n",
      "progress :20%:99%\n",
      "Process iterasive_result/model_3_20_2\n",
      "progress :26%:99%\n",
      "Process iterasive_result/model_3_60_2\n",
      "progress :33%:99%\n",
      "Process iterasive_result/model_5_3_2\n",
      "plot progress:7%\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'iterasive_result/model_5_3_2/epoch007.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4b4d13d051e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'progress :{0}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0maplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/adv/activation_plot/__init__.py\u001b[0m in \u001b[0;36mplot_data\u001b[0;34m(data_path, X_test, colors)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plot progress:{0}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_progress\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mplot_progress\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mactivation_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mactivation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_data_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iterasive_result/model_5_3_2/epoch007.npz'"
     ]
    }
   ],
   "source": [
    "import activation_plot as aplt\n",
    "import os\n",
    "X_test = aplt.data_grid(grid=200,square_len=2)\n",
    "colors = aplt.get_color(X_test)\n",
    "\n",
    "first_layer = [3,5,9,20,60,90]\n",
    "second_layer = [3,5,9,20,60,90]\n",
    "if __name__ == '__main__':\n",
    "    data_path_list = []\n",
    "    for i in first_layer:\n",
    "        for j in second_layer:\n",
    "            path = 'iterasive_result/model_'+str(i)+'_'+str(j)+'_2'\n",
    "            if os.path.exists(path):\n",
    "                data_path_list.append(path)\n",
    "    progress = 0\n",
    "    for data_path in data_path_list:\n",
    "        print('progress :{0}%'.format(int(progress*100/len(data_path_list))))\n",
    "        progress += 1\n",
    "        aplt.plot_data(data_path,X_test,colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
